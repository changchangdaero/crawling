import json
import time
from openai import OpenAI

from dotenv import load_dotenv
import os

# .env ë¡œë“œ
load_dotenv()

# ================================
# 0. OpenAI (GPT-4o-mini) ì„¤ì •
# ================================

api_key = os.getenv("gpt_key")
if not api_key:
    raise RuntimeError("âŒ .env ì— gpt_key ê°’ì´ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# âœ… ì—¬ê¸°ì„œ ì§„ì§œ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
client = OpenAI(api_key=api_key)

OPENAI_MODEL_NAME = "gpt-4o-mini"


# ================================
# 1. ì…ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
# ================================

INPUT_FILE = "step2_articles_with_content.json"  # 2ë‹¨ê³„ ê²°ê³¼ (ë³¸ë¬¸ í¬í•¨)
OUTPUT_FILE = "step3_articles_with_summary_and_groups.json"  # 3ë‹¨ê³„ ê²°ê³¼

# í•œ ê¸°ì‚¬ë‹¹ ë³¸ë¬¸ì„ ì „ë¶€ ë„£ìœ¼ë©´ ë„ˆë¬´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ, ì•ë¶€ë¶„ë§Œ ì˜ë¼ì„œ ë³´ëƒ„
MAX_CONTENT_CHARS = 1200


def load_articles(input_file: str):
    """
    step2ì—ì„œ ë§Œë“  ê¸°ì‚¬ + ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸ JSON ë¶ˆëŸ¬ì˜¤ê¸°.
    êµ¬ì¡°: [{id, query, title, url, content}, ...]
    """
    with open(input_file, "r", encoding="utf-8") as f:
        articles = json.load(f)
    print(f"ğŸ“¥ ìš”ì•½/ê·¸ë£¹í•‘ ëŒ€ìƒ ê¸°ì‚¬ ê°œìˆ˜: {len(articles)}")
    return articles


def build_brief_articles(articles):
    """
    LLMì— ë„˜ê¸¸ ê°„ëµ ë²„ì „ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°.
    - id, title, url, content_snippet ë§Œ í¬í•¨
    - content_snippet: ë³¸ë¬¸ ì• MAX_CONTENT_CHARS ê¸€ì
    """
    brief_list = []
    for a in articles:
        content = (a.get("content") or "").strip()
        if len(content) > MAX_CONTENT_CHARS:
            content_snippet = content[:MAX_CONTENT_CHARS] + "\n...(ì´í•˜ ìƒëµ)"
        else:
            content_snippet = content

        brief_list.append(
            {
                "id": a.get("id"),
                "title": a.get("title"),
                "url": a.get("url"),
                "content": content_snippet,
            }
        )
    return brief_list


def extract_json_from_text(text: str):
    """
    LLMì´ í˜¹ì‹œ ëª¨ë¥´ê²Œ ì•ë’¤ì— ë»˜ì†Œë¦¬ë¥¼ ì¡°ê¸ˆ ë¶™ì—¬ë„,
    ì¤‘ê°„ì˜ JSON ê°ì²´ë§Œ ì˜ë¼ì„œ íŒŒì‹±í•˜ë„ë¡ í•˜ëŠ” ë³´ì¡° í•¨ìˆ˜.
    (ê·¸ë˜ë„ í”„ë¡¬í”„íŠ¸ì—ì„œ JSONë§Œ ì¶œë ¥í•˜ë¼ê³  ë¹¡ì„¸ê²Œ ë§í•´ë‘ )
    """
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        raise ValueError("JSON í˜•ì‹ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ")
    sliced = text[start : end + 1]
    return json.loads(sliced)


def summarize_and_group_with_llm(brief_articles):
    """
    ì—¬ëŸ¬ ê¸°ì‚¬ ì •ë³´ë¥¼ í•œ ë²ˆì— LLMì— ë„˜ê²¨ì„œ:
    1) ê° ê¸°ì‚¬ summary_ko ìƒì„±
    2) ë‚´ìš©ì´ ìœ ì‚¬í•˜ê±°ë‚˜ ì‚¬ì‹¤ìƒ ê°™ì€ ê¸°ì‚¬ë¼ë¦¬ ê·¸ë£¹í•‘ ì •ë³´ ìƒì„±

    ğŸ‘‰ ì—¬ê¸°ì„œ GPT-4o-minië¥¼ ì‚¬ìš©.
    """

    articles_json = json.dumps(brief_articles, ensure_ascii=False, indent=2)

    prompt = f"""
ë„ˆëŠ” í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì •ë¶„ì„ ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” ë„ìš°ë¯¸ì•¼.

ì•„ë˜ JSON ë°°ì—´ articlesì—ëŠ” ì—¬ëŸ¬ ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë³´ê°€ ë“¤ì–´ ìˆë‹¤.
ê° ì›ì†Œì—ëŠ” id, title, url, content ê°€ ìˆë‹¤.
content ëŠ” ê¸°ì‚¬ ë³¸ë¬¸ ì „ì²´ í˜¹ì€ ì•ë¶€ë¶„ì´ë‹¤.

articles:
{articles_json}

ë„ˆì˜ ì—­í• ì€ ë‘ ê°€ì§€ë‹¤.

1) ê° ê¸°ì‚¬ì— ëŒ€í•´ ê°ì •ë¶„ì„ì— ì“°ê¸° ì¢‹ì€ ìš”ì•½ summary_koë¥¼ ìƒì„±í•œë‹¤.
   - summary_koëŠ” í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•œë‹¤.
   - ë¬¸ì¥ ìˆ˜ëŠ” ììœ ì§€ë§Œ, ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ 1~4ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•œë‹¤.
   - ì¸ì‚¬ë§ì´ë‚˜ ìê¸°ì†Œê°œ ì—†ì´ ë°”ë¡œ ìš”ì•½ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•œë‹¤.
   - ê¸°ì‚¬ì—ì„œ ë§í•˜ëŠ” í•µì‹¬ ì‚¬ê±´/ì£¼ì œ, ê´€ë ¨ ê¸°ì—…/ì¸ë¬¼/ê¸°ê´€, ì£¼ìš” ìˆ˜ì¹˜(íˆ¬ì ê·œëª¨, ì‹¤ì , ì†ì‹¤ ë“±)ê°€ ìˆìœ¼ë©´ ê°€ëŠ¥í•œ í¬í•¨í•œë‹¤.
   - ê¸°ì‚¬ ì „ì²´ì˜ í†¤(í˜¸ì¬, ì•…ì¬, ìš°ë ¤, ê°ˆë“±, ì¤‘ë¦½ì  ë¶„ì„ ë“±)ì´ ë“œëŸ¬ë‚˜ë„ë¡ ì“´ë‹¤.
   - ìƒˆë¡œìš´ ì˜ê²¬ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ê³ , ê¸°ì‚¬ì— ì‹¤ì œë¡œ ë“±ì¥í•˜ëŠ” í‰ê°€/ë¶„ìœ„ê¸°ë§Œ ë°˜ì˜í•œë‹¤.
   - ë¬¸ì¥ì€ ëª¨ë‘ í‰ì„œí˜•ìœ¼ë¡œ ëë‚¸ë‹¤.

2) ì„œë¡œ ë‚´ìš©ì´ ì‹¤ì§ˆì ìœ¼ë¡œ ë™ì¼í•˜ê±°ë‚˜, ê°™ì€ ë‰´ìŠ¤ ì´ë²¤íŠ¸ë¥¼ ì•½ê°„ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì „í•˜ëŠ” ì¤‘ë³µ ê¸°ì‚¬ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤.
   - ê°™ì€ ê¸°ì—…/ì¸ë¬¼/ì‚¬ê±´/ë‚ ì§œ/ìˆ˜ì¹˜ ë“±ì„ ê³µìœ í•˜ë©°, ì‚¬ì‹¤ìƒ ê°™ì€ ë‰´ìŠ¤ë¥¼ ë°˜ë³µ ë³´ë„í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ë©´ ê°™ì€ ê·¸ë£¹ì— ë„£ëŠ”ë‹¤.
   - ì œëª©ì´ ë‹¤ë¥´ë”ë¼ë„, ë‚´ìš©ì´ ê°™ì€ ì‚¬ê±´ì„ ë‹¤ë£¨ë©´ ê°™ì€ ê·¸ë£¹ì´ë‹¤.
   - í•œ ê·¸ë£¹ì€ 2ê°œ ì´ìƒì˜ ê¸°ì‚¬ idë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤. (1ê°œë§Œ ìˆìœ¼ë©´ ê·¸ë£¹ìœ¼ë¡œ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.)
   - ì„œë¡œ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë‹¨ë… ê¸°ì‚¬ëŠ” ê·¸ë£¹ì— í¬í•¨ì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤.

ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. ë‹¤ë¥¸ ì„¤ëª… ë¬¸ì¥ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼.

{{
  "articles": [
    {{
      "id": 1,
      "summary_ko": "ì´ê³³ì— id=1 ê¸°ì‚¬ì— ëŒ€í•œ ìš”ì•½ ë¬¸ì¥"
    }},
    {{
      "id": 2,
      "summary_ko": "ì´ê³³ì— id=2 ê¸°ì‚¬ì— ëŒ€í•œ ìš”ì•½ ë¬¸ì¥"
    }}
    // ëª¨ë“  ê¸°ì‚¬ì— ëŒ€í•´ 1ê°œì”© id, summary_ko ìŒì„ ë„£ëŠ”ë‹¤.
  ],
  "groups": [
    {{
      "group_id": 1,
      "article_ids": [1, 3, 5],
      "reason": "ì˜ˆ: ì‚¼ì„±ì „ì ì‚¬ì¥ë‹¨ ì¸ì‚¬ ë°œí‘œë¥¼ ë‹¤ë£¬ ì¤‘ë³µ ê¸°ì‚¬ë“¤"
    }},
    {{
      "group_id": 2,
      "article_ids": [2, 4],
      "reason": "ì˜ˆ: ê°™ì€ ë°˜ë„ì²´ íˆ¬ì ê³„ì•½ ê´€ë ¨ ê¸°ì‚¬ë“¤"
    }}
    // ì¤‘ë³µ ê¸°ì‚¬ê°€ ì—†ë‹¤ë©´ groupsëŠ” ë¹ˆ ë°°ì—´ [] ë¡œ ë‘”ë‹¤.
  ]
}}
"""

    # OpenAI Chat Completions API í˜¸ì¶œ (GPT-4o-mini)
    completion = client.chat.completions.create(
        model=OPENAI_MODEL_NAME,
        messages=[
            {
                "role": "system",
                "content": "ë„ˆëŠ” í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ìš”ì•½ê³¼ ì¤‘ë³µ ê¸°ì‚¬ ê·¸ë£¹í•‘ì„ ìœ„í•œ ë„ìš°ë¯¸ì•¼. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´.",
            },
            {
                "role": "user",
                "content": prompt,
            },
        ],
        temperature=0.2,
    )

    content = completion.choices[0].message.content.strip()
    if not content:
        raise RuntimeError("LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ")

    try:
        parsed = extract_json_from_text(content)
    except Exception as e:
        print("âš ï¸ LLM JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸ ì¼ë¶€ ì¶œë ¥:")
        print(content[:500])
        raise e

    return parsed


def main():
    # 1) ê¸°ì‚¬ + ë³¸ë¬¸ ë¡œë“œ
    articles = load_articles(INPUT_FILE)

    if not articles:
        print("âš ï¸ ì²˜ë¦¬í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2) LLMì— ë„˜ê¸¸ ê°„ë‹¨ ë²„ì „ ìƒì„±
    brief_articles = build_brief_articles(articles)

    print("\n=== GPT-4o-mini ìš”ì•½ + ì¤‘ë³µ ê·¸ë£¹í•‘ í˜¸ì¶œ ===")
    print(f"   ì „ë‹¬í•  ê¸°ì‚¬ ìˆ˜: {len(brief_articles)}")
    time.sleep(0.5)

    # 3) LLM í˜¸ì¶œ
    result = summarize_and_group_with_llm(brief_articles)

    # result ì˜ˆì‹œ:
    # {
    #   "articles": [{"id": 1, "summary_ko": "..."} ...],
    #   "groups": [{"group_id": 1, "article_ids": [...], "reason": "..."} ...]
    # }

    # GPT ì‘ë‹µì—ì„œ id â†’ summary ë§¤í•‘ (idë¥¼ strë¡œ í†µì¼í•´ì„œ ì•ˆì „í•˜ê²Œ)
    article_summaries = {
        str(a["id"]): a["summary_ko"] for a in result.get("articles", [])
    }

    # 4) ì›ë˜ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì— summary_ko ë¶™ì´ê¸°
    merged_articles = []
    missing_summary = 0

    for a in articles:
        aid = a.get("id")
        summary = article_summaries.get(str(aid))
        if not summary:
            missing_summary += 1
            summary = ""  # ë¹„ì–´ ìˆìœ¼ë©´ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì²˜ë¦¬í•´ë„ ë¨

        merged_articles.append(
            {
                "id": aid,
                "query": a.get("query"),
                "title": a.get("title"),
                "url": a.get("url"),
                "content": a.get("content"),
                "summary_ko": summary,
            }
        )

    groups = result.get("groups", [])

    # 5) ì½˜ì†”ì— ìš”ì•½ ê²°ê³¼ ì¶œë ¥
    print("\n==============================")
    print("=== ê¸°ì‚¬ë³„ ìš”ì•½ ê²°ê³¼ ì¶œë ¥ ===")
    print("==============================")
    for a in merged_articles:
        print(f"\n[ID {a['id']}] {a['title']}")
        print(f"URL: {a['url']}")
        if a["summary_ko"]:
            print(f"ìš”ì•½: {a['summary_ko']}")
        else:
            print("ìš”ì•½: (ì—†ìŒ)")

    # 6) ì½˜ì†”ì— ê·¸ë£¹í•‘ ê²°ê³¼ ì¶œë ¥
    print("\n==============================")
    print("=== ì¤‘ë³µ ê·¸ë£¹í•‘ ê²°ê³¼ ì¶œë ¥ ===")
    print("==============================")
    if not groups:
        print("ê·¸ë£¹ ì—†ìŒ (ì¤‘ë³µ ê¸°ì‚¬ ê·¸ë£¹ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.)")
    else:
        for g in groups:
            gid = g.get("group_id")
            ids = g.get("article_ids", [])
            reason = g.get("reason", "")
            print(f"\n[ê·¸ë£¹ {gid}] ê¸°ì‚¬ IDë“¤: {ids}")
            print(f"ì´ìœ : {reason}")

    # 7) ìµœì¢… ê²°ê³¼ ì €ì¥
    output_data = {
        "articles": merged_articles,
        "groups": groups,
    }

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print("\nâœ… GPT-4o-mini ìš”ì•½ + ì¤‘ë³µ ê·¸ë£¹í•‘ ì™„ë£Œ")
    print(f"   ê¸°ì‚¬ ìˆ˜: {len(merged_articles)}")
    print(f"   ê·¸ë£¹ ìˆ˜: {len(groups)}")
    if missing_summary > 0:
        print(f"   âš ï¸ ìš”ì•½ì´ ë¹„ì–´ ìˆëŠ” ê¸°ì‚¬ ìˆ˜: {missing_summary}")
    print(f"   ì €ì¥ íŒŒì¼: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
